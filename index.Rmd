---
title: "index.Rmd"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(compmus)
library(plotly)
library(dplyr)
library(purrr)
library(ggplot2)

```

### Keys throughout the song: Europapa

```{r}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)
key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

get_tidy_audio_analysis("0uHrMbMv3c78398pIANDqR") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "acentre", norm = "manhattan"
      )
  ) |>
  compmus_match_pitch_template(key_templates, "aitchison", "manhattan") |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", fill = "Distance")

```

***
**What we see:**
Here we can see how the song Europapa from Joost Klein changes keys throughout the song. It is visible that the song starts in a B minor and changes to a C# minor, which stays the main key. 

### Tempo sd vs tempo mean: 2 albums of lauv

```{r}

bebop <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "4oVP4N93yIQh6iOsGUiyVh"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
bigband <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "2cjIvuw4VVOQSeUAZfNiqY"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
jazz <-
  bebop |>
  mutate(genre = "How I am feeling") |>
  bind_rows(bigband |> mutate(genre = "I met you when you were 18"))

jazz |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
**What we see:**
In this plot the tempo standard deviation is shown against the mean tempo for two albums of the same artist, Lauv. It compares the album `How I am feeling` from 2020 and the album `I met you when I was 18Â´ from 2018. Also the duration of the songs are visible.

### Study Objectives

**A** **Comparative Study of Spotify Wrapped Playlists and Daily Mixes**

For this research I will be comping my personalized music library, wrapped music from 2023, with Spotify's daily mixes to assess the quality of Spotify's playlists. The daily mixes are made by spotify, based on my previous listening behaviour. I want to explore two research questions. Firstly, I want to see how closely my 2023 wrapped music matches the songs in Spotify's playlists. Secondly, I'm investigating whether Spotify organizes its playlists logically by grouping similar music together or if they vary widely. This will be done by comparing the daily mixes with each other. Additionally, I'm interested in whether Spotify only includes music from my most-listened genres or if they include songs outside of my usual preferences. My wrapped music contains mostly English pop music, but also has the occasional rock/rap and dutch songs. It contains 100 songs. Spotify provides six daily mixes, which all contain 50 songs and differ from each other in artists. The comparison of my wrapped and the daily mixes is intriguing because Spotify's algorithms are based on my typical listening habits. Although the daily mixes are influenced by all my listening behaviors, and not only by the behaviour in 2023, I believe it's still a valid comparison since my music taste hasn't changed much since last year. There are some songs in my wrapped that are in a different style then the others, one example is the song Mansion by NF, which could be categorized as hiphop. I want to explore how these outliers are represented in the daily mixes.

### How similar are the wrapped and dailymixes? (Danceability vs Energy)

```{r}
library(ggplot2)
library(spotifyr)

howImfeeling <- get_album_tracks("3ZuE680xhR1A4bCFGvL8mi")
Lauv <- get_artist_audio_features("5JZ7CnR6gTvEMKX4g70Amv")
dailymix1 <- get_playlist_audio_features("", "7q9rJndtwhJU0I1NnIQ0Mb")
dailymix2 <- get_playlist_audio_features("", "3Q7MLkx3oC8SAyQHKKyxFb")
dailymix3 <- get_playlist_audio_features("", "29qms80NIUefqQETWqEkih")
dailymix4 <- get_playlist_audio_features("", "7cX6TM5B1pnMya6mRIr1y1")
dailymix5 <- get_playlist_audio_features("", "6LdtUdGsF399LonyHPc3OG")
dailymix6 <- get_playlist_audio_features("", "0ZWKIhgkIHSHImcwnSmIgv")
wrapped <- get_playlist_audio_features("", "3t3AcAxKQhFuWkD4791XWP")
lina <- get_track_audio_features("1wwVk5Zzzc7dRZ3SjHhQIB")
lina_analysis <- get_track_audio_analysis("1wwVk5Zzzc7dRZ3SjHhQIB")

wrapped_subset <- wrapped[, c("danceability", "energy")]
dailymix1_subset <- dailymix1[, c("danceability", "energy")]
lina_subset <- lina[, c("danceability", "energy")]

plot_ly() %>%
  add_trace(data = wrapped_subset, type = "scatter", mode = "markers",
            x = ~danceability, y = ~energy, color = ~factor("Wrapped"),
            marker = list(color = "blue"), alpha = 0.8, name = "Wrapped") %>%
  add_trace(data = dailymix1_subset, type = "scatter", mode = "markers",
            x = ~danceability, y = ~energy, color = ~factor("Dailymix1"),
            marker = list(color = "green"), alpha = 0.8, name = "Dailymix1") %>%
  add_trace(data = lina_subset, type = "scatter", mode = "markers",
            x = ~danceability, y = ~energy, color = ~factor("Lina"),
            marker = list(color = "red"), alpha = 0.8, name = "Lina") %>%
  layout(
    xaxis = list(title = "Danceability"),
    yaxis = list(title = "Energy"),
    title = "Danceability vs Energy",
    legend = list(orientation = "h"),
    margin = list(l = 80, r = 80, b = 30, t = 30)
  )


```

------------------------------------------------------------------------

**What we see:**

In this plot you can see the enenrgy against the danceability of both the wrapped and the dailymix1 dataset. It is visible that the range of danceability and energy of both playlists are very different from each other. It is interesting to compare this to see how much the music of the dailymix relates to the kind of music in the wrapped playlist. However this is just one of the daily mixes, for further analysis it would be interesting to look at the result of several daily mixes.

### Chromachart: Wings by Lina Meike

```{r}
# Load the data
chroma <- get_tidy_audio_analysis("10RX2JZjVT3Rm9bS6XPEy5") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

# Perform necessary transformations
chroma <- chroma |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() 

# Create ggplot object
p <- ggplot(chroma, aes(x = start + duration / 2, width = duration, y = pitch_class, fill = value)) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

# Convert ggplot object to Plotly object
p_plotly <- ggplotly(p)

# Display the interactive plot
p_plotly

```

------------------------------------------------------------------------

**What we see:**

In the picture we can see the chromagram of the song Wings by Lina Meike. This is a song played by a friend of mine.

### Self Similarity matrix: Eyes closed by Ed Sheeran

```{r}
ed_sheeran <-
  get_tidy_audio_analysis("3p7XQpdt8Dr6oMXSvRZ9bg") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches, timbre)

compmus_long_distance(
  ed_sheeran |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  ed_sheeran |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(title = "Eyes Closed - Ed Sheeran Pitch", x = NULL, y = NULL) +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)
```


***
**What we see:**

Tbh I have a lot of difficulties making sense of this plot and I don't really understand what the use of it is, so if anyone can help in the feedback I would be very greatfull!

### Timbre Similarity matrix: Uncharted by Kensington

```{r}
kensington <-
  get_tidy_audio_analysis("1OJcaSbK9DBaxHExACplwA") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches, timbre)

compmus_long_distance(
  kensington |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  kensington |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = timbre,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(title = "Eyes Closed - Ed Sheeran Timbre", x = NULL, y = NULL) +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)
```


***
**What we see:**
Here we can see the timbre throughout the song Uncharted by Kensington. The music switches from singing with a guitar to using background singers, drums and other instruments. You can clearly see that the song has a build up in instruments. For the first part only one voice and the guitar is audible, after that the song keeps building up with adding drums and background voices. At some point the timbre changes again (see the yellow lines at 3/4 of the song). In the music only a voice is audible at this part, after that the other instruments and background voices start playing. In the end the song is calming down with only a guitar and main voice. 

